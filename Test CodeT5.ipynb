{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70afe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 uninstall -y apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9d7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"PYTHONPATH\"]=\"/home/shariff/AVATAR\"\n",
    "!export PYTHONIOENCODING=utf-8\n",
    "!export PYTHONPATH=/home/shariff/AVATAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fb9238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from codet5.configs import add_args, set_seed, set_dist\n",
    "from codet5.utils import get_filenames, get_elapse_time, load_and_cache_gen_data\n",
    "from codet5.models import build_or_load_gen_model\n",
    "import multiprocessing\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from tqdm import tqdm\n",
    "from evaluation import smooth_bleu\n",
    "from evaluation.bleu import _bleu\n",
    "from evaluation.CodeBLEU import calc_code_bleu\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e50429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    do_test = True\n",
    "    model_type = \"codet5\"\n",
    "    config_name = \"Salesforce/codet5-base\" \n",
    "    tokenizer_name = \"Salesforce/codet5-base\"\n",
    "    model_name_or_path = \"Salesforce/codet5-base\"\n",
    "    load_model_path = \"/home/shariff/AVATAR/codet5/program/java2python/checkpoint-best-ppl/pytorch_model.bin\"\n",
    "    task = \"translate\"\n",
    "    sub_task = \"java-python\"\n",
    "    data_dir = \"/home/shariff/AVATAR/data\"\n",
    "    cache_path = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "    output_dir = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "    res_dir = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "    max_source_length = 510 \n",
    "    max_target_length = 510 \n",
    "    beam_size = 10\n",
    "    eval_batch_size = 4\n",
    "    local_rank = -1\n",
    "    no_cuda=False\n",
    "    seed = 1234\n",
    "    data_num = -1\n",
    "    add_task_prefix=True\n",
    "    res_fn = ''\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cde3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_epoch(args, eval_data, eval_examples, model, tokenizer, split_tag):\n",
    "    print(\"  ***** Running bleu evaluation on {} data*****\".format(split_tag))\n",
    "    print(\"  Num examples = \", len(eval_examples))\n",
    "    print(\"  Batch size = \", args.eval_batch_size)\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    if args.data_num == -1:\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size, num_workers=4, pin_memory=True\n",
    "        )\n",
    "    else:\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    pred_ids = []\n",
    "    bleu, codebleu = 0.0, 0.0\n",
    "    for batch in tqdm(eval_dataloader, total=len(eval_dataloader), desc=\"Eval bleu for {} set\".format(split_tag)):\n",
    "        source_ids = batch[0].to(args.device)\n",
    "        source_mask = source_ids.ne(tokenizer.pad_token_id)\n",
    "        with torch.no_grad():\n",
    "            if args.model_type == 'roberta':\n",
    "                preds = model(source_ids=source_ids, source_mask=source_mask)\n",
    "                top_preds = [pred[0].cpu().numpy() for pred in preds]\n",
    "            else:\n",
    "                preds = model.generate(source_ids,\n",
    "                                       attention_mask=source_mask,\n",
    "                                       use_cache=True,\n",
    "                                       num_beams=args.beam_size,\n",
    "                                       early_stopping=args.task == 'summarize',\n",
    "                                       max_length=args.max_target_length)\n",
    "                top_preds = list(preds.cpu().numpy())\n",
    "            pred_ids.extend(top_preds)\n",
    "    pred_nls = [tokenizer.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=False) for id in pred_ids]\n",
    "\n",
    "    output_fn = os.path.join(args.res_dir, \"{}.output\".format(split_tag))\n",
    "    gold_fn = os.path.join(args.res_dir, \"{}.gold\".format(split_tag))\n",
    "    src_fn = os.path.join(args.res_dir, \"{}.src\".format(split_tag))\n",
    "\n",
    "    if args.task in ['defect']:\n",
    "        target_dict = {0: 'false', 1: 'true'}\n",
    "        golds = [target_dict[ex.target] for ex in eval_examples]\n",
    "        eval_acc = np.mean([int(p == g) for p, g in zip(pred_nls, golds)])\n",
    "        result = {'em': eval_acc, 'bleu': 0, 'codebleu': 0}\n",
    "\n",
    "        with open(output_fn, 'w') as f, open(gold_fn, 'w') as f1, open(src_fn, 'w') as f2:\n",
    "            for pred_nl, gold in zip(pred_nls, eval_examples):\n",
    "                f.write(pred_nl.strip() + '\\n')\n",
    "                f1.write(target_dict[gold.target] + '\\n')\n",
    "                f2.write(gold.source.strip() + '\\n')\n",
    "            print(\"Save the predictions into %s\", output_fn)\n",
    "    else:\n",
    "        dev_accs, predictions = [], []\n",
    "        with open(output_fn, 'w', encoding='utf8') as f, \\\n",
    "                open(gold_fn, 'w', encoding='utf8') as f1, \\\n",
    "                open(src_fn, 'w', encoding='utf8') as f2:\n",
    "            for pred_nl, gold in zip(pred_nls, eval_examples):\n",
    "                dev_accs.append(pred_nl.strip() == gold.target.strip())\n",
    "                if args.task in ['summarize']:\n",
    "                    predictions.append(str(gold.idx) + '\\t' + pred_nl)\n",
    "                    f.write(str(gold.idx) + '\\t' + pred_nl.strip() + '\\n')\n",
    "                    f1.write(str(gold.idx) + '\\t' + gold.target.strip() + '\\n')\n",
    "                    f2.write(str(gold.idx) + '\\t' + gold.source.strip() + '\\n')\n",
    "                else:\n",
    "                    print(\"INPUT:\", gold.source.strip())\n",
    "                    print()\n",
    "                    print(\"OUTPUT:\", pred_nl.strip())\n",
    "                    print()\n",
    "                    print(\"GROUND TRUTH:\", gold.target.strip())\n",
    "                    f.write(pred_nl.strip() + '\\n')\n",
    "                    f1.write(gold.target.strip() + '\\n')\n",
    "                    f2.write(gold.source.strip() + '\\n')\n",
    "\n",
    "        if args.task in ['summarize']:\n",
    "            (goldMap, predictionMap) = smooth_bleu.computeMaps(predictions, gold_fn)\n",
    "            bleu = round(smooth_bleu.bleuFromMaps(goldMap, predictionMap)[0], 2)\n",
    "        else:\n",
    "            bleu = round(_bleu(gold_fn, output_fn), 2)\n",
    "\n",
    "        em = np.mean(dev_accs) * 100\n",
    "        result = {'em': em, 'bleu': bleu}\n",
    "\n",
    "    print(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        print(\"  {} = {}\".format(key, str(round(result[key], 4))))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4e9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 128\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "set_dist(args)\n",
    "set_seed(args)\n",
    "config, model, tokenizer = build_or_load_gen_model(args)\n",
    "model.to(args.device)\n",
    "pool = multiprocessing.Pool(args.cpu_cont)\n",
    "args.train_filename, args.dev_filename, args.test_filename = get_filenames(args.data_dir, args.task, args.sub_task)\n",
    "fa = open(os.path.join(args.output_dir, 'summary.log'), 'a+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea69d441",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_examples, eval_data = load_and_cache_gen_data(\n",
    "    args, args.test_filename, pool, tokenizer, 'test', only_src=True, is_sample=False\n",
    ")\n",
    "model = model.module if hasattr(model, 'module') else model\n",
    "result = eval_bleu_epoch(args, eval_data, eval_examples, model, tokenizer, 'test')\n",
    "test_bleu, test_em = result['bleu'], result['em']\n",
    "test_codebleu = result['codebleu'] if 'codebleu' in result else 0\n",
    "result_str = \"bleu-4: %.2f, em: %.4f, codebleu: %.4f\\n\" % (test_bleu, test_em, test_codebleu)\n",
    "print(\"result_str\", result_str)\n",
    "fa.write(result_str)\n",
    "if args.res_fn:\n",
    "    with open(args.res_fn, 'a+') as f:\n",
    "        f.write('[Time: {}] {}\\n'.format(get_elapse_time(t0), file))\n",
    "        f.write(result_str)\n",
    "fa.write(\"Finish and take {}\".format(get_elapse_time(t0)))\n",
    "fa.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80c2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
