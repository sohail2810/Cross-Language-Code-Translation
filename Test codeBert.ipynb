{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9d7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"PYTHONPATH\"]=\"/home/shariff/AVATAR\"\n",
    "!export PYTHONIOENCODING=utf-8\n",
    "!export PYTHONPATH=/home/shariff/AVATAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0fb9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from io import open\n",
    "from itertools import cycle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    "    RobertaTokenizer\n",
    ")\n",
    "\n",
    "from evaluation.bleu import _bleu\n",
    "from codebert.model import Seq2Seq\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'roberta': (RobertaConfig, RobertaModel, RobertaTokenizer)\n",
    "}\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e50429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Args:\n",
    "#     do_test = True\n",
    "#     model_type = \"codet5\"\n",
    "#     config_name = \"Salesforce/codet5-base\" \n",
    "#     tokenizer_name = \"Salesforce/codet5-base\"\n",
    "#     model_name_or_path = \"Salesforce/codet5-base\"\n",
    "#     load_model_path = \"/home/shariff/AVATAR/codet5/program/java2python/checkpoint-best-ppl/pytorch_model.bin\"\n",
    "#     task = \"translate\"\n",
    "#     sub_task = \"java-python\"\n",
    "#     data_dir = \"/home/shariff/AVATAR/data\"\n",
    "#     cache_path = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "#     output_dir = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "#     res_dir = \"/home/shariff/AVATAR/codet5/program/java2python\"\n",
    "#     max_source_length = 510 \n",
    "#     max_target_length = 510 \n",
    "#     beam_size = 10\n",
    "#     eval_batch_size = 8\n",
    "#     local_rank = -1\n",
    "#     no_cuda=False\n",
    "#     seed = 1234\n",
    "#     data_num = -1\n",
    "#     add_task_prefix=True\n",
    "#     res_fn = ''\n",
    "    \n",
    "# args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cde3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    ## Required parameters  \n",
    "    model_type = \"roberta\"\n",
    "    model_name_or_path = \"microsoft/codebert-base\"\n",
    "    tokenizer_name = \"roberta-base\"\n",
    "    output_dir = \"/home/shariff/AVATAR/codebert/program/java2python\"\n",
    "    load_model_path = \"/home/shariff/AVATAR/codebert/program/java2python/checkpoint-best-ppl/pytorch_model.bin\"\n",
    "    ## Other parameters\n",
    "#     train_filename = \n",
    "#     dev_filename = \n",
    "#     test_filename = \n",
    "    config_name = \"roberta-base\"\n",
    "    max_source_length = 510\n",
    "    max_target_length = 510\n",
    "    do_train = False\n",
    "    do_eval = False\n",
    "    do_test = True\n",
    "    do_lower_case = True\n",
    "    no_cuda = False\n",
    "    train_batch_size = 8\n",
    "    eval_batch_size = 16\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 5e-5\n",
    "    beam_size = 10\n",
    "    weight_decay = 0.0\n",
    "    adam_epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "    num_train_epochs = 30\n",
    "    max_steps = -1\n",
    "    eval_steps = 1\n",
    "    train_steps = -1\n",
    "    warmup_steps = 0\n",
    "    local_rank = -1\n",
    "    seed = 42\n",
    "    max_patience = 10\n",
    "    data_dir = \"/home/shariff/AVATAR/data\"\n",
    "    source = \"java\"\n",
    "    target = \"python\"\n",
    "    log_file = \"/home/shariff/AVATAR/codebert/program/java2python/finetune.log\"\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dedea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    \"\"\"set random seed.\"\"\"\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4e9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print arguments\n",
    "if args.log_file is not None:\n",
    "    fh = logging.FileHandler(args.log_file)\n",
    "    logger.addHandler(fh)\n",
    "logger.info(args)\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "    args.n_gpu = 1\n",
    "logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s\",\n",
    "               args.local_rank, device, args.n_gpu, bool(args.local_rank != -1))\n",
    "args.device = device\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "# make dir if output_dir not exist\n",
    "if os.path.exists(args.output_dir) is False:\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name, do_lower_case=args.do_lower_case)\n",
    "\n",
    "# budild model\n",
    "encoder = model_class.from_pretrained(args.model_name_or_path, config=config)\n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    config=config,\n",
    "    beam_size=args.beam_size,\n",
    "    max_length=args.max_target_length,\n",
    "    sos_id=tokenizer.cls_token_id,\n",
    "    eos_id=tokenizer.sep_token_id\n",
    ")\n",
    "\n",
    "if args.load_model_path is not None:\n",
    "    logger.info(\"reload model from {}\".format(args.load_model_path))\n",
    "    model.load_state_dict(torch.load(args.load_model_path))\n",
    "\n",
    "###### Count and print number of parameters ######\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(\"num. model params: {} (num. trained: {})\".format(total_params, total_trainable_params))\n",
    "\n",
    "model.to(device)\n",
    "if args.local_rank != -1:\n",
    "    # Distributed training\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"\n",
    "        )\n",
    "    model = DDP(model)\n",
    "\n",
    "elif args.n_gpu > 1:\n",
    "    # multi-gpu training\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63894ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, args, stage=None):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # source\n",
    "        source_tokens = tokenizer.tokenize(example.source)[:args.max_source_length - 2]\n",
    "        source_tokens = [tokenizer.cls_token] + source_tokens + [tokenizer.sep_token]\n",
    "        source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "        source_mask = [1] * (len(source_tokens))\n",
    "        padding_length = args.max_source_length - len(source_ids)\n",
    "        source_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        source_mask += [0] * padding_length\n",
    "\n",
    "        # target\n",
    "        if stage == \"test\":\n",
    "            target_tokens = tokenizer.tokenize(\"None\")\n",
    "        else:\n",
    "            target_tokens = tokenizer.tokenize(example.target)[:args.max_target_length - 2]\n",
    "\n",
    "        target_tokens = [tokenizer.cls_token] + target_tokens + [tokenizer.sep_token]\n",
    "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "        target_mask = [1] * len(target_ids)\n",
    "        padding_length = args.max_target_length - len(target_ids)\n",
    "        target_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        target_mask += [0] * padding_length\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_index,\n",
    "                source_ids,\n",
    "                target_ids,\n",
    "                source_mask,\n",
    "                target_mask,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d82ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "\n",
    "    def __init__(self, source, target):\n",
    "        self.source = source\n",
    "        self.target = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13665976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_examples(data_dir, source, target, part):\n",
    "    \"\"\"Read examples from filename.\"\"\"\n",
    "    examples = []\n",
    "    src_file_name = os.path.join(data_dir, part + '.java-python.' + source)\n",
    "    tgt_file_name = os.path.join(data_dir, part + '.java-python.' + target)\n",
    "    with open(src_file_name, encoding='utf8') as f1, \\\n",
    "            open(tgt_file_name, encoding='utf8') as f2:\n",
    "        for src, tgt in zip(f1, f2):\n",
    "            examples.append(\n",
    "                Example(source=src.strip(), target=tgt.strip())\n",
    "            )\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefedf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            example_id,\n",
    "            source_ids,\n",
    "            target_ids,\n",
    "            source_mask,\n",
    "            target_mask,\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.source_ids = source_ids\n",
    "        self.target_ids = target_ids\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea69d441",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_examples = read_examples(args.data_dir, args.source, args.target, 'test')\n",
    "eval_features = convert_examples_to_features(eval_examples, tokenizer, args, stage='test')\n",
    "all_source_ids = torch.tensor([f.source_ids for f in eval_features], dtype=torch.long)\n",
    "all_source_mask = torch.tensor([f.source_mask for f in eval_features], dtype=torch.long)\n",
    "eval_data = TensorDataset(all_source_ids, all_source_mask)\n",
    "\n",
    "# Calculate bleu\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "model.eval()\n",
    "p = []\n",
    "for batch in tqdm(eval_dataloader, total=len(eval_dataloader)):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    source_ids, source_mask = batch\n",
    "    with torch.no_grad():\n",
    "        preds = model(source_ids=source_ids, source_mask=source_mask)\n",
    "        for pred in preds:\n",
    "            t = pred[0].cpu().numpy()\n",
    "            t = list(t)\n",
    "            if 0 in t:\n",
    "                t = t[:t.index(0)]\n",
    "            text = tokenizer.decode(t, clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "accs = []\n",
    "with open(os.path.join(args.output_dir, \"test.output\"), 'w', encoding='utf-8') as f, \\\n",
    "        open(os.path.join(args.output_dir, \"test.gold\"), 'w', encoding='utf-8') as f1:\n",
    "    for hyp, gold in zip(p, eval_examples):\n",
    "        f.write(hyp + '\\n')\n",
    "        f1.write(gold.target + '\\n')\n",
    "        accs.append(hyp == gold.target)\n",
    "dev_bleu = round(_bleu(\n",
    "    os.path.join(args.output_dir, \"test.gold\"),\n",
    "    os.path.join(args.output_dir, \"test.output\")\n",
    "), 2)\n",
    "logger.info(\"  %s = %s \" % (\"bleu-4\", str(dev_bleu)))\n",
    "logger.info(\"  %s = %s \" % (\"xMatch\", str(round(np.mean(accs) * 100, 4))))\n",
    "logger.info(\"  \" + \"*\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5f309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
